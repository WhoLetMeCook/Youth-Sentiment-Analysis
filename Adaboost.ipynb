{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom datasets import load_dataset, Dataset\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import AdaBoostClassifier\nimport nltk\n\nnltk.download('punkt')\n\n# Load datasets\nimdb = load_dataset('stanfordnlp/imdb')\nsst2 = load_dataset('glue', 'sst2')\n\n# Separate train and test splits\nimdbTr = imdb['train']\nimdbTe = imdb['test']\nsst2Tr = sst2['train']\nsst2Te = sst2['validation']\n\n# Combine datasets\ntrainList = [example for example in imdbTr] + [example for example in sst2Tr]\ntestList = [example for example in imdbTe] + [example for example in sst2Te]\n\ntrain = Dataset.from_list(trainList)\ntest = Dataset.from_list(testList)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sth = 100\n\ndef add_is_long(example, threshold=sth):\n    text = example.get('text', example.get('sentence', ''))\n    tokens = word_tokenize(str(text))\n    example['is_long'] = int(len(tokens) > threshold)\n    return example\n\n# Add is_long feature to the datasets\ntrain = train.map(add_is_long)\ntest = test.map(add_is_long)\n\ntrainList = [example for example in train]\ntestList = [example for example in test]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encodeDataTFIDF(data, vectorizer):\n    texts = [example['text'] for example in data]\n    labels = [example['label'] for example in data]\n    X = vectorizer.transform(texts)\n    return X, labels\n\nvectorizer = TfidfVectorizer(max_features=10000, tokenizer=word_tokenize)\ntrain_texts = [example['text'] for example in trainList]\nvectorizer.fit(train_texts)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 10\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\naccuracies = []\n\nfor fold, (train_index, test_index) in enumerate(kf.split(trainList)):\n    train_data = [trainList[i] for i in train_index]\n    val_data = [trainList[i] for i in test_index]\n\n    X_train_fold, y_train_fold = encodeDataTFIDF(train_data, vectorizer)\n    X_val_fold, y_val_fold = encodeDataTFIDF(val_data, vectorizer)\n\n    # Add is_long feature\n    X_train_fold = np.hstack([X_train_fold, np.array([train_data[i]['is_long'] for i in range(len(train_data))]).reshape(-1, 1)])\n    X_val_fold = np.hstack([X_val_fold, np.array([val_data[i]['is_long'] for i in range(len(val_data))]).reshape(-1, 1)])\n\n    # Use sklearn.ensemble AdaBoostClassifier\n    adaBoost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, random_state=42), n_estimators=50, random_state=42)\n    adaBoost.fit(X_train_fold, y_train_fold)\n\n    # Predict on validation fold\n    final_predictions = adaBoost.predict(X_val_fold)\n\n    test_accuracy = accuracy_score(y_val_fold, final_predictions)\n    accuracies.append(test_accuracy)\n\n    print(f\"Fold {fold + 1} - Accuracy: {test_accuracy:.4f}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_accuracy = np.mean(accuracies)\nprint(f\"Average Accuracy: {avg_accuracy:.4f}\")\n","metadata":{},"execution_count":null,"outputs":[]}]}